{
    "content": [
        {
            "type": "title",
            "text": "Concetti base di probabilità"
        },
        {
            "type": "subtitle",
            "text": "In questo capitolo introduciamo i concetti fondamentali della teoria della probabilità, essenziali per comprendere fenomeni aleatori e processi stocastici."
        },
        {
            "type": "heading",
            "level": 3,
            "text": "Teoria della Probabilità"
        },
        {
            "type": "paragraph",
            "text": "La <highlight>teoria della probabilità</highlight> è un ramo della matematica che studia i fenomeni aleatori e fornisce strumenti per quantificare l'incertezza associata a eventi casuali. In particolare, quando effettuiamo una misura, stiamo collezionando risultati con un certo grado di variabilità; la statistica ci permette di arrivare a una conclusione generale partendo da un insieme frammentario di dati. Per fare ciò, ci si confronta con modelli teorici, da qui teoria della probabilità."
        },
        {
            "type": "paragraph",
            "text": "Diamo alcune definizioni fondamentali:"
        },
        {
            "type": "list",
            "items": [
                "<highlight>Spazio degli eventi</highlight>: È l'insieme di tutti i possibili risultati di un esperimento casuale.",
                "<highlight>Evento</highlight>: È un sottoinsieme dello spazio degli eventi, cioè una collezione di uno o più risultati elementari che soddisfano una certa condizione. Gli eventi possono essere semplici (un singolo risultato, come \"esce il numero 3\") o composti (più risultati, come \"esce un numero pari\"). Ad esempio, nel lancio di un dado, l'evento \"uscire un numero pari\" è {2, 4, 6}.",
                "<highlight>Permutazioni</highlight>: Sono disposizioni di oggetti in un ordine specifico. Il numero di permutazioni di \\(n\\) oggetti distinti è dato da \\(n!\\) (fattoriale di \\(n\\)). Ad esempio, le permutazioni delle lettere A, B e C sono ABC, ACB, BAC, BCA, CAB, CBA."
            ]
        },
        {
            "type": "heading",
            "level": 4,
            "text": "Eventi composti"
        },
        {
            "type": "paragraph",
            "text": "Gli eventi composti sono eventi che appunto possono essere suddivisi in più eventi semplici. Nel caso in cui si lanci un dado, un evento composto potrebbe essere \"uscire un numero pari\". Per analizzarli, dobbiamo prima determinare la situazione in cui ci troviamo, ossia:"
        },
        {
            "type": "list",
            "items": [
                "Nel caso di <highlight>campionamento con reinserimento</highlight>, il numero di eventi composti è dato dal numero di esiti possibili elevato alla potenza del numero di esperimenti. $$N_{eventi} = n^{k}$$ dove \\(n\\) è il numero di esiti possibili e \\(k\\) il numero di esperimenti.",
                "Nel caso di <highlight>campionamento senza reinserimento</highlight>, dipende se l'ordine con cui si presentano gli eventi è rilevante o meno. Se l'ordine è rilevante, il numero di eventi composti è dato dalla formula delle disposizioni:</br> $$N_{eventi} = \\frac{n!}{(n-k)!}$$ dove \\(n\\) è il numero di esiti possibili e \\(k\\) il numero di esperimenti. Mentre invece, se l'ordine non è rilevante, il numero di eventi composti è dato dalla formula delle combinazioni: $$N_{eventi} = \\frac{n!}{k!(n-k)!}$$ dove \\(n\\) è il numero di esiti possibili e \\(k\\) il numero di esperimenti. Quest'ultimo è anche conosciuto come <highlight>coefficiente binomiale</highlight> e si indica con \\(C(n, k)\\) oppure \\(\\binom{n}{k}\\)."
            ]
        },
        {
            "type": "paragraph",
            "text": "Esiste inoltre una \"generalizzazione\" del coefficiente binomiale, chiamata <highlight>coefficiente multinomiale</highlight>, che estende il concetto a più di due gruppi. Il coefficiente multinomiale rappresenta il numero di modi in cui è possibile suddividere un insieme di \\(n\\) elementi in \\(m\\) gruppi di dimensioni specificate \\(k_1, k_2, \\ldots, k_m\\), dove la somma delle dimensioni dei gruppi è uguale a \\(n\\) (cioè, \\(k_1 + k_2 + \\ldots + k_m = n\\)). Si calcola come:"
        },
        {
            "type": "math",
            "text": "M(n; k_1, k_2, \\ldots, k_m) = \\frac{n!}{k_1! k_2! \\ldots k_m!}"
        },
        {
            "type": "heading",
            "level": 3,
            "text": "Probabilità matematica e assiomi di Kolmogorov"
        },
        {
            "type": "paragraph",
            "text": "La <highlight>probabilità matematica</highlight> è una misura numerica che quantifica la possibilità che un evento si verifichi. Viene espressa come un numero compreso tra 0 e 1, dove 0 indica l'impossibilità dell'evento e 1 indica la certezza dell'evento (*). La probabilità di un evento \\(E\\) è denotata come \\(P(E)\\)."
        },
        {
            "type": "paragraph",
            "text": "<div style=\"font-size: smaller; color: #999999;\">(*) Nel caso in cui si abbia a che fare con spazi continui, al contrario degli spazi discreti, la probabilità di un singolo evento può essere zero, ma questo non significa che l'evento non possa verificarsi.</div>"
        },
        {
            "type": "paragraph",
            "text": "Gli assiomi di Kolmogorov sono i principi fondamentali su cui si basa la teoria della probabilità:"
        },
        {
            "type": "list",
            "items": [
                "<highlight>Non negatività</highlight>: La probabilità di qualsiasi evento \\(A\\) è sempre non negativa: \\(P(A) ≥ 0\\).",
                "<highlight>Normalizzazione</highlight>: La probabilità dell'intero spazio degli eventi \\(S\\) è uguale a 1: \\(P(S) = 1\\).",
                "<highlight>Additività</highlight>: Se \\(A\\) e \\(B\\) sono eventi mutuamente esclusivi (cioè non possono verificarsi contemporaneamente), allora la probabilità che si verifichi \\(A\\) o \\(B\\) è data dalla somma delle loro probabilità: \\(P(A \\cup B) = P(A) + P(B)\\)."
            ]
        },
        {
            "type": "paragraph",
            "text": "Distinzione importante riguardo le proprietà degli eventi:"
        },
        {
            "type": "list",
            "items": [
                "Due eventi \\(A\\) e \\(B\\) si dicono <highlight>mutuamente esclusivi</highlight> se non possono verificarsi contemporaneamente. Ossia, \\(P(A \\cap B) = 0\\).",
                "Due eventi \\(A\\) e \\(B\\) si dicono <highlight>indipendenti</highlight> se la probabilità che si verifichi \\(A\\) non è influenzata dal fatto che \\(B\\) si verifichi o meno. Ossia, \\(P(A | B) = P(A)\\)."
            ]
        },
        {
            "type": "paragraph",
            "text": "Da notare che un evento può essere o mutuamente esclusivo o indipendente, ma non entrambi, a meno che almeno uno dei due abbia probabilità zero. Infatti, per la regola del prodotto delle probabilità, se \\(A\\) e \\(B\\) sono indipendenti, allora \\(P(A \\cap B) = P(A) * P(B)\\). Se \\(A\\) e \\(B\\) fossero anche mutuamente esclusivi, allora \\(P(A \\cap B) = 0\\), il che implicherebbe che almeno uno dei due eventi ha probabilità zero."
        },
        {
            "type": "heading",
            "level": 3,
            "text": "Probabilità empirica"
        },
        {
            "type": "paragraph",
            "text": "La <highlight>probabilità empirica</highlight> si basa sull'osservazione e sull'esperimento. Viene calcolata come il rapporto tra il numero di volte in cui un evento si verifica \\(M\\) e il numero totale di prove effettuate \\(N\\). Quando \\(N\\) tende a infinito, \\(\\frac{M}{N}\\) converge a \\(P(E)\\)."
        },
        {
            "type": "heading",
            "level": 3,
            "text": "Probabilità condizionata e Teorema di Bayes"
        },
        {
            "type": "paragraph",
            "text": "La <highlight>probabilità condizionata</highlight> è la probabilità che un evento \\(A\\) si verifichi dato che un altro evento \\(B\\) è già accaduto. Si denota come \\(P(A | B)\\) \" P di A dato B \" e si calcola con la formula:"
        },
        {
            "type": "math",
            "text": "P(A | B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{se } P(B) > 0"
        },
        {
            "type": "paragraph",
            "text": "Dove:"
        },
        {
            "type": "list",
            "items": [
                "\\(P(A | B)\\) è la probabilità di \\(A\\) dato \\(B\\).",
                "\\(P(A \\cap B)\\) è la probabilità che si verifichino entrambi gli eventi \\(A\\) e \\(B\\).",
                "\\(P(B)\\) è la probabilità di \\(B\\)."
            ]
        },
        {
            "type": "paragraph",
            "text": "Attenzione: la probabilità condizionata non è simmetrica, cioè in generale \\(P(A | B) \\neq P(B | A)\\). Infatti se \\(A\\) è la probabilità di pescare una carta nera e \\(B\\) è la probabilità di pescare una carta di fiori, allora \\(P(A | B) = 1\\) (se so che la carta è di fiori, allora so che è nera), mentre \\(P(B | A) = 1/2\\) (se so che la carta è nera, non so se è di fiori o di picche)."
        },
        {
            "text": "Con la definizione di probabilità condizionata,possiamo fornire una generalizzazione della regola del prodotto delle probabilità per eventi non necessariamente indipendenti, ossia:"
        },
        {
            "type": "math",
            "text": "P(A \\cap B) = P(A | B) \\cdot P(B) = P(B | A) \\cdot P(A)"
        },
        {
            "type": "heading",
            "level": 4,
            "text": "Teorema di Bayes e statistica bayesiana"
        },
        {
            "type": "paragraph",
            "text": "Il <highlight>Teorema di Bayes</highlight> fornisce un modo per aggiornare le probabilità alla luce di nuove informazioni. La formula del teorema di Bayes è:"
        },
        {
            "type": "math",
            "text": "P(A | B) = \\frac{P(B | A) \\cdot P(A)}{P(B)}, \\quad \\text{se } P(B) > 0"
        },
        {
            "type": "paragraph",
            "text": "Dove:"
        },
        {
            "type": "list",
            "items": [
                "\\(P(A | B)\\) è la probabilità di \\(A\\) dato \\(B\\) (probabilità a posteriori).",
                "\\(P(B | A)\\) è la probabilità di \\(B\\) dato \\(A\\) (verosimiglianza).",
                "\\(P(A)\\) è la probabilità di \\(A\\) (probabilità a priori).",
                "\\(P(B)\\) è la probabilità di \\(B\\) (evidenza)."
            ]
        },
        {
            "type": "paragraph",
            "text": "La formula è ottenuta dalla relazione precedente sulla regola del prodotto e lega così le due probabilità condizionate \\(P(A | B)\\) e \\(P(B | A)\\)."
        },
        {
            "type": "example",
            "content": [
                {
                    "type": "paragraph",
                    "text": "Supponiamo di avere un test diagnostico per una malattia che ha le seguenti caratteristiche:"
                },
                {
                    "type": "list",
                    "items": [
                        "La probabilità che una persona abbia la malattia (prevalenza) è \\(P(M) = 0.01\\) (1%).",
                        "La probabilità che il test sia positivo se la persona ha la malattia è \\(P(T+ | M) = 0.99\\) (sensibilità del test).",
                        "La probabilità che il test sia negativo se la persona non ha la malattia è \\(P(T- | M^c) = 0.95\\) (specificità del test)."
                    ]
                },
                {
                    "type": "paragraph",
                    "text": "Ora, supponiamo che una persona faccia il test e risulti positiva. Vogliamo calcolare la probabilità che questa persona abbia effettivamente la malattia, cioè \\(P(M | T+)\\)."
                },
                {
                    "type": "paragraph",
                    "text": "Per applicare il teorema di Bayes, abbiamo bisogno di calcolare \\(P(T+)\\), la probabilità che il test sia positivo. Possiamo farlo usando la legge delle probabilità totali:"
                },
                {
                    "type": "math",
                    "text": "P(T+) = P(T+ | M) \\cdot P(M) + P(T+ | M^c) \\cdot P(M^c)"
                },
                {
                    "type": "math",
                    "text": "= 0.99 \\cdot 0.01 + (1 - 0.95) \\cdot 0.99 = 0.0099 + 0.0495 = 0.0594"
                },
                {
                    "type": "paragraph",
                    "text": "Ora possiamo applicare il teorema di Bayes:"
                },
                {
                    "type": "math",
                    "text": "P(M | T+) = \\frac{P(T+ | M) \\cdot P(M)}{P(T+)} = \\frac{0.99 \\cdot 0.01}{0.0594} \\approx 0.1667"
                },
                {
                    "type": "paragraph",
                    "text": "Quindi, nonostante il test sia positivo, la probabilità che la persona abbia effettivamente la malattia è solo circa il 16.67%. Questo esempio illustra l'importanza di considerare la prevalenza della malattia e le caratteristiche del test diagnostico quando si interpretano i risultati dei test."
                }
            ]
        },
        {
            "type": "paragraph",
            "text": "La maggiore differenza tra la statistica bayesiana e quella frequentista risiede nell'interpretazione della probabilità:"
        },
        {
            "type": "list",
            "items": [
                "Nella <highlight>statistica frequentista</highlight>, la probabilità è interpretata come la frequenza relativa di un evento che si verifica in un gran numero di prove ripetute. In questo contesto, i parametri del modello sono considerati fissi ma sconosciuti, e l'obiettivo è stimarli utilizzando i dati osservati.",
                "Nella <highlight>statistica bayesiana</highlight>, la probabilità è interpretata come un grado di credenza o fiducia in un evento. In questo contesto, i parametri del modello sono considerati variabili casuali con distribuzioni di probabilità a priori, che vengono aggiornate alla luce dei dati osservati per ottenere distribuzioni di probabilità a posteriori."
            ]
        },
        {
            "type": "heading",
            "level": 3,
            "text": "Distribuzioni di probabilità"
        },
        {
            "type": "paragraph",
            "text": "Introduciamo ora una variabile il cui valore numerico indica il verificarsi di un particolare risultato, o di un gruppo di risultati, e la chiameremo <highlight>variabile casuale</highlight>, o <highlight>variabile stocastica</highlight>, o anche <highlight>variable aleatoria</highlight>. Questa variabile può essere di due tipi:"
        },
        {
            "type": "list",
            "items": [
                "<highlight>Variabile casuale discreta</highlight>: convenzionalmente identificata con la lettera \"k\", assume un insieme finito o numerabile di valori distinti. Ad esempio, il numero di teste ottenute lanciando una moneta un certo numero di volte.",
                "<highlight>Variabile casuale continua</highlight>: convenzionalmente identificata con la lettera \"x\", può assumere qualsiasi valore all'interno di un intervallo continuo. Ad esempio, l'altezza di una persona o la temperatura in una città."
            ]
        },
        {
            "type": "paragraph",
            "text": "Una <highlight>distribuzione di probabilità</highlight> è la probabilità \\(P(k_i)\\) che la variabile \\(k\\) assuma un certo valore \\(k_i\\). Inoltre, possiamo identificare \\(P(k_i)\\) come la mappa che associa tutti i possibili valori \\(k_i\\) con le loro rispettive probabilità \\(P(k_i)\\). Per trovare \\(P(k_i)\\), si sommano le probabilità di tutti gli eventi elementari che, secondo la definizione della variabile \\(k\\), risultano in quel valore specifico \\(k_i\\)."
        },
        {
            "type": "paragraph",
            "text": "Ricordiamo che una distribuzione di probabilità è sempre una funzione a valori non negativi e deve essere sempre normalizzata, cioè la somma di tutte le probabilità deve essere uguale a 1:"
        },
        {
            "type": "math",
            "text": "\\displaystyle \\sum_{i=1}^N P(k_i) = 1"
        },
        {
            "type": "example",
            "content": [
                {
                    "type": "paragraph",
                    "text": "Consideriamo il lancio di due dadi a sei facce. Definiamo la variabile casuale \\(k\\) come la somma ottenuta dal lancio dei dadi. I possibili valori di \\(k\\) sono 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 e 12. Poiché il dado è equo, ogni faccia ha la stessa probabilità di uscire, che è \\(\\frac{1}{6}\\)."
                },
                {
                    "type": "list",
                    "items": [
                        "\\(P(k = 2) = \\frac{1}{36}\\) \\(\\text{(1,1)})\\)",
                        "\\(P(k = 3) = \\frac{2}{36}\\) \\(\\text{(1,2),(2,1)})\\)",
                        "\\(P(k = 4) = \\frac{3}{36}\\) \\(\\text{(1,3),(2,2),(3,1)})\\)",
                        "\\(P(k = 5) = \\frac{4}{36}\\) \\(\\text{(1,4),(2,3),(3,2),(4,1)})\\)",
                        "\\(P(k = 6) = \\frac{5}{36}\\) \\(\\text{(1,5),(2,4),(3,3),(4,2),(5,1)})\\)",
                        "\\(P(k = 7) = \\frac{6}{36}\\) \\(\\text{(1,6),(2,5),(3,4),(4,3),(5,2),(6,1)})\\)",
                        "\\(P(k = 8) = \\frac{5}{36}\\) \\(\\text{(2,6),(3,5),(4,4),(5,3),(6,2)})\\)",
                        "\\(P(k = 9) = \\frac{4}{36}\\) \\(\\text{(3,6),(4,5),(5,4),(6,3)})\\)",
                        "\\(P(k = 10) = \\frac{3}{36}\\) \\(\\text{(4,6),(5,5),(6,4)})\\)",
                        "\\(P(k = 11) = \\frac{2}{36}\\) \\(\\text{(5,6),(6,5)})\\)",
                        "\\(P(k = 12) = \\frac{1}{36}\\) \\(\\text{(6,6)})\\)"
                    ]
                },
                {
                    "type": "paragraph",
                    "text": "Questo insieme di valori e delle loro probabilità costituisce la distribuzione di probabilità della variabile casuale \\(k\\). Ciascuna singola probabilità, \\(P(k_i)\\), è un elemento di tale distribuzione."
                },
                {
                    "type": "paragraph",
                    "text": "Possiamo infine verificare che la somma delle probabilità è effettivamente 1:"
                },
                {
                    "type": "math",
                    "text": "\\frac{1 + 2 + 3 + 4 + 5 + 6 + 5 + 4 + 3 + 2 + 1}{36} = \\frac{36}{36} = 1"
                }
            ]
        },
        {
            "type": "heading",
            "level": 4,
            "text": "Indicatori statistici per una distribuzione di probabilità"
        },
        {
            "type": "paragraph",
            "text": "Il <highlight>valore di aspettazione</highlight> è l'analogo al valor medio per una distrubizione di frequenze, con la differenza che la media descrive una distruzione di dati sperimentali, mentre il valore di aspettazione descrive una distribuzione teorica di probabilità. Si calcola come:"
        },
        {
            "type": "math",
            "text": "< k > = \\sum_{k=1}^N k_i P(k_i)"
        },
        {
            "type": "paragraph",
            "text": "Inoltre, il valore di aspettazione coincide con il massimo della distribuzione se la distribuzione ha un valore massimo ed è simmetrica. Infine, nel caso di una variabile somma di una o più variabili, esso è la somma dei valori di aspettazione delle singole variabili."
        },
        {
            "type": "paragraph",
            "text": "Abbiamo poi la <highlight>varianza</highlight>, che misura la dispersione dei valori della variabile casuale intorno al valore di aspettazione. Si calcola come:"
        },
        {
            "type": "math",
            "text": "\\sigma_k^2 = < (k - < k >)^2 > = \\sum_{k=1}^N (k_i - < k >)^2 P(k_i) \\quad \\text{ o, analogamente } \\quad \\sigma_k^2 = < k^2 > - < k >^2"
        },
        {
            "type": "paragraph",
            "text": "C'è l'<highlight>indice della larghezza di distribuzione</highlight>, che altro non è che la radice quadrata della varianza. Si calcola come:"
        },
        {
            "type": "math",
            "text": "\\sigma_k = \\sqrt{\\sigma_k^2}"
        },
        {
            "type": "paragraph",
            "text": "Infine, c'è l'<highlight>asimmetria della distribuzione</highlight>, che misura la simmetria della distribuzione rispetto al suo valore di aspettazione. Si calcola come:"
        },
        {
            "type": "math",
            "text": "\\gamma = \\frac{< (k - < k >)^3 >}{\\sigma_k^3} = \\frac{\\sum_{k=1}^N (k_i - < k >)^3 P(k_i)}{\\sigma_k^3}"
        },
        {
            "type": "heading",
            "level": 3,
            "text": "Distribuzione di Bernoulli o binomiale"
        },
        {
            "type": "paragraph",
            "text": "Iniziamo considerando n ripetizioni di un esperimento in cui un certo evento E si verifica con probabilità p. La variabile casuale k rappresenta il numero di successi in n prove. La distribuzione di Bernoulli descrive un singolo esperimento, ossia nel caso \\(n=1\\), mentre la distribuzione binomiale descrive il numero di successi in più n esperimenti indipendenti. Si calcola come:"
        },
        {
            "type": "math",
            "text": "P(k; n, p) = \\binom{n}{k} p^k (1-p)^{n-k}"
        },
        {
            "type": "paragraph",
            "text": "Dove:"
        },
        {
            "type": "list",
            "items": [
                "\\(P(k; n, p)\\) è la probabilità di ottenere \\(k\\) successi in \\(n\\) prove.",
                "\\(\\binom{n}{k}\\) è il coefficiente binomiale, che rappresenta il numero di modi in cui si possono scegliere \\(k\\) successi da \\(n\\) prove.",
                "\\(p\\) è la probabilità di successo in una singola prova.",
                "\\(1-p\\) è la probabilità di insuccesso in una singola prova."
            ]
        },
        {
            "type": "paragraph",
            "text": "Controlliamo che la distribuzione binomiale sia correttammente normalizzata:"
        },
        {
            "type": "math",
            "text": "(a + b)^n = \\sum_{k=0}^n \\binom{n}{k} a^k (b)^{n-k} \\rightarrow \\sum_{k=0}^n \\binom{n}{k} p^k (1-p)^{n-k} = (p + (1-p))^n = 1^n = 1"
        },
        {
            "type": "paragraph",
            "text": "Procediamo adesso a mettere in relazione il valore di aspettazione con la distribuzione binomiale. Ricordando che \\(< k > = \\displaystyle \\sum_{k} k_i P(k_i)\\), otteniamo: \\[< k > = \\sum_{k=0}^n k \\binom{n}{k} p^k (1-p)^{n-k} = \\sum_{k=0}^n k \\frac{n(n-1)!}{k(k-1)!(n-k)!}p \\cdot p^k(1-p)^{n-k}\\] Le due \\(k\\) si cancellano, portiamo fuori la \\(n\\) e la \\(p\\) e sostituiamo \\(n = n - 1\\) e \\(k = k - 1\\): \\[= np \\sum_{k=1}^n \\binom{n-1}{k-1} p^{k-1} (1-p)^{(n-1)-(k-1)} = np (p + (1-p))^{n-1} = np\\]"
        },
        {
            "type": "paragraph",
            "text": "Quindi, il valore di aspettazione per una distribuzione binomiale è:"
        },
        {
            "type": "math",
            "text": "< k > = np"
        },
        {
            "type": "paragraph",
            "text": "Allo stesso modo, calcoliamo la varianza \\(\\sigma_k^2\\): \\[\\sigma_k^2 = < k^2 > - < k >^2 = \\sum_{k=0}^n k^2 \\binom{n}{k} p^k (1-p)^{n-k} - (np)^2 = np(1-p) + (np)^2 - (np)^2 = np(1-p)\\]"
        },
        {
            "type": "paragraph",
            "text": "Quindi, la varianza per una distribuzione binomiale è:"
        },
        {
            "type": "math",
            "text": "\\sigma_k^2 = np(1-p)"
        },
        {
            "type": "paragraph",
            "text": "Da cui segue che la deviazione standard è:"
        },
        {
            "type": "math",
            "text": "\\sigma_k = \\sqrt{np(1-p)}"
        },
        {
            "type": "paragraph",
            "text": "Infine, la deviazione standard relativa è:"
        },
        {
            "type": "math",
            "text": "\\frac{\\sigma_k}{< k >} = \\frac{\\sqrt{np(1-p)}}{np} = \\frac{\\sqrt{(1-p)}}{\\sqrt{np}}"
        },
        {
            "type": "paragraph",
            "text": "Notiamo come all'aumentare del numero di prove n, la deviazione standard relativa diminuisce, indicando una maggiore concentrazione dei risultati intorno al valore atteso."
        },
        {
            "type": "paragraph",
            "text": "La media e la varianza crescono come \\(n\\), la deviazione standard cresce come \\(\\sqrt{n}\\), e infine la deviazione standard relativa diminuisce come \\(\\frac{1}{\\sqrt{n}}\\)."
        },
        {
            "type": "example",
            "content": [
                {
                    "type": "heading",
                    "level": 4,
                    "text": "Qual'è la probabilità di ottenere quattro volte 3 in 10 lanci di un dado?"
                },
                {
                    "type": "paragraph",
                    "text": "In questo caso, l'evento E è ottenere un 3, che ha una probabilità di \\(p = \\frac{1}{6}\\). Vogliamo calcolare la probabilità di ottenere \\(k = 4\\) successi (ottenere un 3) in \\(n = 10\\) lanci del dado. Utilizziamo la distribuzione binomiale:"
                },
                {
                    "type": "math",
                    "text": "P(4; 10, \\frac{1}{6}) = \\binom{10}{4} \\left(\\frac{1}{6}\\right)^4 \\left(\\frac{5}{6}\\right)^{10-4} = 210 \\cdot 7.7 \\cdot 10^{-4} \\cdot 0.33 \\approx 0.054 \\approx 5.4\\%"
                },
                {
                    "type": "heading",
                    "level": 4,
                    "text": "Qual'è la probabilità di ottenere 10 croci su 20 lanci di una moneta?"
                },
                {
                    "type": "paragraph",
                    "text": "In questo caso, l'evento E è ottenere una croce, che ha una probabilità di \\(p = \\frac{1}{2}\\). Vogliamo calcolare la probabilità di ottenere \\(k = 10\\) successi (ottenere una croce) in \\(n = 20\\) lanci della moneta. Prima di tutto calcoliamo:"
                },
                {
                    "type": "list",
                    "items": [
                        "\\( < k > = np = 20 \\cdot \\frac{1}{2} = 10\\)",
                        "\\(\\sigma_k = \\sqrt{np(1-p)} = \\sqrt{20 \\cdot \\frac{1}{2} \\cdot \\frac{1}{2}} = \\sqrt{5} \\approx 2.236\\)",
                        "\\(\\frac{\\sigma_k}{< k >} = \\frac{2.236}{10} \\approx 0.2236\\)"
                    ]
                },
                {
                    "type": "paragraph",
                    "text": "Adesso possiamo calcolare la probabilità utilizzando la distribuzione binomiale:"
                },
                {
                    "type": "math",
                    "text": "P(10; 20, \\frac{1}{2}) = \\binom{20}{10} \\left(\\frac{1}{2}\\right)^{10} \\left(\\frac{1}{2}\\right)^{20-10} = 184756 \\cdot 0.00000095367431640625 \\approx 0.176 \\approx 17.6\\%"
                },
                {
                    "type": "heading",
                    "level": 4,
                    "text": "Qual'è la probabilità di ottenere 100 croci su 200 lanci di una moneta?"
                },
                {
                    "type": "paragraph",
                    "text": "In questo caso, l'evento E è ottenere una croce, che ha una probabilità di \\(p = \\frac{1}{2}\\). Vogliamo calcolare la probabilità di ottenere \\(k = 100\\) successi (ottenere una croce) in \\(n = 200\\) lanci della moneta. Prima di tutto calcoliamo:"
                },
                {
                    "type": "list",
                    "items": [
                        "\\( < k > = np = 200 \\cdot \\frac{1}{2} = 100\\)",
                        "\\(\\sigma_k = \\sqrt{np(1-p)} = \\sqrt{200 \\cdot \\frac{1}{2} \\cdot \\frac{1}{2}} = \\sqrt{50} \\approx 7.071\\)",
                        "\\(\\frac{\\sigma_k}{< k >} = \\frac{7.071}{100} \\approx 0.07071\\)"
                    ]
                },
                {
                    "type": "paragraph",
                    "text": "Adesso possiamo calcolare la probabilità utilizzando la distribuzione binomiale:"
                },
                {
                    "type": "math",
                    "text": "P(100; 200, \\frac{1}{2}) = \\binom{200}{100} \\left(\\frac{1}{2}\\right)^{100} \\left(\\frac{1}{2}\\right)^{200-100} = 9.054 \\cdot 10^{57} \\cdot 7.888 \\cdot 10^{-31} \\approx 0.176 \\approx 17.6\\%"
                },
                {
                    "type": "paragraph",
                    "text": "Notiamo che, come detto in precedenza, all'aumentare del numero di prove, la probabilità di ottenere il valore atteso rimane costante, mentre la deviazione standard relativa diminuisce, indicando una maggiore concentrazione dei risultati intorno al valore atteso."
                }
            ]
        },
        {
            "type": "heading",
            "level": 3,
            "text": "Moto Browniano e random walk"
        },
        {
            "type": "paragraph",
            "text": "Il <highlight>moto browniano</highlight> è il movimento casuale di particelle microscopiche sospese in un fluido, causato dalle collisioni con le molecole del fluido stesso. Questo fenomeno è stato osservato per la prima volta da Robert Brown nel 1827. Il moto browniano può essere modellato matematicamente come un <highlight>random walk</highlight> (passeggiata casuale), in cui una particella compie una serie di passi in direzioni casuali, più precisamente associamo alla possibilità di andare a sinistra o a destra egual valore \\(p = \\frac{1}{2}\\). A questo punto, possiamo utilizzare la distribuzione binomiale per descrivere la probabilità di trovare la particella a una certa distanza dalla posizione iniziale dopo un certo numero di passi. E' interessante notare come la larghezza dell'istogramma cresce come \\(L\\sqrt{N}\\) e la deviazione standard, dal valore \\(\\frac{\\sqrt{N}}{2}\\) cresce come \\(\\sigma = \\sqrt{N}\\)."
        }
    ]
}